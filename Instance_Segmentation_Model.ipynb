{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVPdNCqHQZyN1hnIVWoFdw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataenthusiast092/InstanceSegmentationModel/blob/main/Instance_Segmentation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instance Segmentation Model"
      ],
      "metadata": {
        "id": "axoJheteLwRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to the Problem at hand"
      ],
      "metadata": {
        "id": "IYD8ywHsMgSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem involves training a deep learning model to perform instance segmentation on a video. Instance segmentation is a computer vision task that combines object detection and semantic segmentation. The goal is to identify and label each individual object instance within an image or video with a unique color. The requirement is to submit a video where each detected object instance is represented by a distinct color. A detailed document explaining the steps taken in the process is also necessary. While submitting code is optional, it's an option to showcase the implementation.\n",
        "\n"
      ],
      "metadata": {
        "id": "7mFSN5c5QR_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is the Key Concept behind the problem?"
      ],
      "metadata": {
        "id": "rZjLfbhKQZaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While Instance Segmentation is a technique that goes beyond object detection by not only identifying objects in an image but also segmenting them pixel by pixel and labeling each instance separately."
      ],
      "metadata": {
        "id": "NVfj7mtcQqWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install tensorflow-gpu\n",
        "# !pip install torch torchvision\n",
        "# !pip install opencv-python\n",
        "# !pip install matplotlib scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5hTdbUKRKSG",
        "outputId": "3869d3c1-0d4d-46f4-b8fb-0ac63e673474"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "pc7_OQLKRsbI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "sY9eRFMjL2yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction to the Data**\n",
        "\n",
        "This dataset contains a large number of segmented nuclei images. The images were acquired under a variety of conditions and vary in the cell type, magnification, and imaging modality (brightfield vs. fluorescence). The dataset is designed to challenge an algorithm's ability to generalize across these variations.\n",
        "\n",
        "Each image is represented by an associated ImageId. Files belonging to an image are contained in a folder with this ImageId. Within this folder are two subfolders:\n",
        "\n",
        "images contains the image file.\n",
        "masks contains the segmented masks of each nucleus. This folder is only included in the training set. Each mask contains one nucleus. Masks are not allowed to overlap (no pixel belongs to two masks).\n",
        "The second stage dataset will contain images from unseen experimental conditions. To deter hand labeling, it will also contain images that are ignored in scoring. The metric used to score this competition requires that your submissions are in run-length encoded format. Please see the evaluation page for details.\n",
        "\n",
        "As with any human-annotated dataset, you may find various forms of errors in the data. You may manually correct errors you find in the training set. The dataset will not be updated/re-released unless it is determined that there are a large number of systematic errors. The masks of the stage 1 test set will be released with the release of the stage 2 test set.\n",
        "\n",
        "1. /stage1_train/* - training set images (images and annotated masks)\n",
        "\n",
        "2. /stage1_test/* - stage 1 test set images (images only, you are predicting the masks)\n",
        "\n",
        "3. /stage2_test/* (released later) - stage 2 test set images (images only, you are predicting the masks)\n",
        "\n",
        "4. **stage1_sample_submission.csv** - a submission file containing the ImageIds for which you must predict during stage 1\n",
        "\n",
        "5. **stage2_sample_submission.csv (released later)** - a submission file containing the ImageIds for which you must predict during stage 2\n",
        "\n",
        "6. **stage1_train_labels.csv** - a file showing the run-length encoded representation of the training images. This is provided as a convenience and is redundant with the mask image files."
      ],
      "metadata": {
        "id": "1oq4XzdweI3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gathering a Labeled Dataset into Training & Validation Sets"
      ],
      "metadata": {
        "id": "3-RdWMHDMl8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the Dataset**\n",
        "\n",
        "1. Data Inspection\n",
        "2. Data Preprocessing\n",
        "3. Handling Missing Annotations\n",
        "4. Removing Outliers\n",
        "5. Balancing Classes\n",
        "6. Data Augmentation\n",
        "7. Data Splitting\n",
        "8. Data Format Loading"
      ],
      "metadata": {
        "id": "OIH6XkuBg6Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Inspection**\n",
        "\n",
        "To-Do:\n",
        "\n",
        "1. Select a representative subset of images and masks from the dataset.\n",
        "\n",
        "2. Manually review these images and masks to identify major anomalies, such as misaligned annotations and potential data corruption.\n",
        "\n",
        "3. Note any instances where annotations do not match the corresponding images.\n",
        "\n",
        "4. Develop automated code to perform checks for missing images within the dataset.\n",
        "\n",
        "5. Implement automated checks to detect discrepancies in dimensions between images and their corresponding masks.\n",
        "\n",
        "6. Utilize code to generate summary statistics, including image sizes and class distributions, to gain insights into data quality.\n",
        "\n",
        "7. Analyze the insights gained from manual and automated inspection to understand the dataset's characteristics and potential issues.\n",
        "\n",
        "8. Combine the insights from both manual and automated inspection to make an initial assessment of the dataset's suitability for instance segmentation.\n",
        "\n",
        "9. Ensure that both manual scrutiny and automated validation processes are thorough, covering potential inconsistencies, errors, or anomalies.\n",
        "\n",
        "10. Based on the combined findings from manual and automated inspection, establish a robust foundation for subsequent data preprocessing and model training."
      ],
      "metadata": {
        "id": "TY9kBnoMiNO3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvThNJFwg8wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary:**\n",
        "\n",
        "In the initial phase of data preparation, a comprehensive 'Data Inspection' was conducted to ensure the quality and suitability of the dataset for the instance segmentation task. This inspection involved a dual approach, combining both manual and automated mechanisms. Manual inspection of a representative subset of images and corresponding masks revealed major anomalies, such as misaligned annotations and potential data corruption, providing valuable insights into the dataset's characteristics. Additionally, automated code was employed to efficiently check for missing images and detect discrepancies in dimensions between images and masks. This automated approach generated summary statistics, including image sizes and class distributions, aiding in the initial assessment of data quality. By combining manual scrutiny with automated validation, the dataset was thoroughly examined for any inconsistencies, errors, or anomalies, setting a robust foundation for subsequent preprocessing and model training."
      ],
      "metadata": {
        "id": "fXT51oJllRk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the Data into Training & Validation Sets"
      ],
      "metadata": {
        "id": "xrfCVTaKMmO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing a Framework and Library"
      ],
      "metadata": {
        "id": "Pk_VcYUSL6pB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Framework: Use Tensorflow & Pytorch"
      ],
      "metadata": {
        "id": "UiqUMrpYM114"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries: Utilize Tensorflow Object Detection API or Detectron2 for PyTorch"
      ],
      "metadata": {
        "id": "o6DIkZrTNKwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select a Model Architecture"
      ],
      "metadata": {
        "id": "uTX1VeLZMC8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose from Architectures like Mask R-CNN, FCN or DeepLab"
      ],
      "metadata": {
        "id": "OSafYD07NZxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained Model: Use COCO pretrained models for a head start"
      ],
      "metadata": {
        "id": "5obeS7wLNZ6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "3OYZMDDyMIP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tune the chosen Model on your Dataset."
      ],
      "metadata": {
        "id": "1usOieZENw6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjust Hyperparameters, Learning Rate & Optimizer"
      ],
      "metadata": {
        "id": "-zzMLuACNxCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor Loss, Accuracy and Other Metrics during Training"
      ],
      "metadata": {
        "id": "UFRw9gftOJ1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "UoCvW0uGMKo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use a mean - Average Precision (mAP) to measure instance segmentation performance\n"
      ],
      "metadata": {
        "id": "Wh9x91raObgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Frame per second (FPS) to assess Inference Speed"
      ],
      "metadata": {
        "id": "xBUL-95yOb0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hardware Configuration for Inference"
      ],
      "metadata": {
        "id": "3x2dsd2-MM8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify the Hardware CPU / GPU used for Inferencing"
      ],
      "metadata": {
        "id": "WwrhbGhLO29w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note the Memory & Processing Power"
      ],
      "metadata": {
        "id": "84WyFwTrO3G1"
      }
    }
  ]
}